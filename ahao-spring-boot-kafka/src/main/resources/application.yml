spring:
  application:
    name: ahao-kafka
  kafka:
    # 生产者和消费者的公共参数
    properties:
      linger.ms: 50 # 当生产端积累的消息达到batch-size或接收到消息linger.ms后,生产者就会将消息提交给kafka
      max.in.flight.requests.per.connection: 1 # 生产者最多同时发送1条消息给Broker, 避免消息无序提交
    admin:
      fail-fast: true # Broker不可用时快速失败
    producer:
      clientId: ${spring.application.name} # 方便broker打印日志定位请求来源
      bootstrap-servers: 127.0.0.1:9092
      acks: all
      retries: 15 # 重试次数, 这个参数需要结合retry.backoff.ms（重试等待间隔）来使用，建议总的重试时间比集群重新选举leader的时间长，这样可以避免生产者过早结束重试导致失败。
      compressionType: "none" # 不开启压缩
      batch-size: 16384 # 发送一批消息的最大数据量
      buffer-memory: 33554432 # 缓冲区默认大小32M
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
    consumer:
      bootstrap-servers: 127.0.0.1:9092
      enable-auto-commit: false
      auto-commit-interval: 2000 # 自动提交的时间间隔
      auto-offset-reset: earliest
      fetchMinSize: 1 # 拉取消息的最小数据量
      fetchMaxWait: 500 # 拉取消息的最大等待时长
      maxPollRecords: 500 # consumer每次批量拉多少条数据
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
    listener:
      ack-mode: MANUAL_IMMEDIATE
      concurrency: 1  # 推荐设置为topic的分区数
